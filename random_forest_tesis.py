# -*- coding: utf-8 -*-
"""Random_Forest_tesis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ff10k4owuoWFqm77qOAH6pAgDEGP4N7w
"""

# Tratamiento de datos
# =================================================================
import numpy as np
import pandas as pd

# Graficos
# =================================================================
import matplotlib.pyplot as plt
import seaborn as sns

# Preprocesamiento y modelado de los datos
# =================================================================
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report, mean_squared_error
# from sklearn.compose import ColumnTransformer
# from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import cross_val_score, train_test_split, RepeatedKFold, GridSearchCV, ParameterGrid
from sklearn.inspection import permutation_importance
import multiprocessing

from sklearn.svm import SVC         # Support Vector Clasification
from sklearn.metrics import f1_score, jaccard_score

from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LinearRegression

from google.oauth2 import service_account
#from google.colab import drive

import gdown
import gspread

import os
import pickle

#Leer el data

import pandas as pd

# Ruta al archivo Excel (o la ruta correcta a tu conjunto de datos)
archivo_excel = 'Data.xlsx'

# Leer el conjunto de datos con pandas
Data = pd.read_excel(archivo_excel)

# Ahora puedes trabajar con el DataFrame en tu código
print(Data.head())
#Data

# Preprocesamiento de los datos para la distribucion
estudiantes_CEPRE = Data.drop(['estudiante','si_no'], axis=1)
Columnas = estudiantes_CEPRE.columns.to_list()
nColumnas = ['P-1','P-2','P-3','P-4','P-5','P-6','P-7']
dfColumnas = dict(zip(Columnas, nColumnas))
estudiantes_CEPRE.rename(columns=dfColumnas, inplace=True)

# Ajuste del modelo y optimización de hiperparámetros
X_train, X_test, y_train, y_test = train_test_split(
    estudiantes_CEPRE.drop(columns = 'ingreso'),
    estudiantes_CEPRE['ingreso'],
    random_state = 123
    )
print(len(X_train), len(X_test), len(y_train), len(y_test))

# Grid Search basado en validación cruzada
# =================================================================================================
param_grid = {'n_estimators': [150], #la data que utiliza
               'max_features': [3, 5, 7], #las preguntas
               'max_depth'   : [None, 3, 10, 20],
               'criterion'   : ['gini', 'entropy']
               }
# Búsqueda por grid search con validación cruzada
grid = GridSearchCV(
    estimator  = RandomForestClassifier(random_state = 123),
    param_grid = param_grid,
    scoring    = 'accuracy',
    n_jobs     = multiprocessing.cpu_count() - 1,
    cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123),
    refit      = True,
    verbose    = 0,
    return_train_score = True
)
# with tf.device('/device:GPU:0'):
m_rf = grid.fit(X = X_train, y = y_train)

# Resultados
resultados = pd.DataFrame(m_rf.cv_results_)
print(resultados.filter(regex = '(param*|mean_t|std_t)').drop(columns = 'params').sort_values('mean_test_score', ascending = False).head(10)) #Encontrar las 10 mejores combinaciones de hiperparametrp en funcion de putaje de prueba

# Obtener la mitad del rango de mean_test_score
mean_test_score_midpoint = resultados['mean_test_score'].min() + (resultados['mean_test_score'].max() - resultados['mean_test_score'].min()) / 2

# Crear un gráfico para mostrar la relación entre n_estimators y mean_test_score
for criterion in param_grid['criterion']:
    subset = resultados[resultados['param_criterion'] == criterion]
    color = 'green' if criterion == 'entropy' else 'red'  # Colorear 'entropy' en verde y 'gini' en rojo
    label = f'{criterion.capitalize()} criterion'
    plt.plot(subset['param_n_estimators'], subset['mean_test_score'], marker='o', color=color, label=label)

plt.axhline(y=mean_test_score_midpoint, color='gray', linestyle='--')  # Línea horizontal en la mitad
plt.xlabel('n_estimators')
plt.ylabel('mean_test_score')
plt.title('Relación entre n_estimators y mean_test_score en RandomForest según el criterio')
plt.legend()
plt.show()

# Mejores hiperparámetros por validación cruzada
# ****************************************************************
print(grid.best_params_, ":", grid.best_score_, grid.scoring)

modelo_final = grid.best_estimator_

# =================================================================================================
# Predicción y evaluación del modelo
# =================================================================================================
predicciones = modelo_final.predict(X = X_test)
print(predicciones[:20])

#Medir el rendimmiento del modelo
mat_confusion = confusion_matrix(
    y_true    = y_test,
    y_pred    = predicciones
    )

#Calcular la precision
accuracy = accuracy_score(
    y_true    = y_test,
    y_pred    = predicciones,
    normalize = True
    )
print(f'Precisión del modelo: {accuracy:.2f}')

print("Matriz de confusión")
print("-------------------")
print(mat_confusion)
print("")
print(f"El accuracy de test es: {100 * accuracy} %")

print(
    classification_report(
        y_true = y_test,
        y_pred = predicciones
    )
)

plt.figure(figsize=(8, 6))
sns.heatmap(mat_confusion, annot=True, fmt='d', cmap='YlGnBu', cbar=False)
plt.xlabel('Etiqueta Real')
plt.ylabel('Etiqueta Predicha')
plt.title('Matriz de Confusión')
plt.show()

# Predicción de probabilidades
# =================================================================================================
predicciones = modelo_final.predict_proba(X = X_test)
print(predicciones[:5, :])

nuevo_modelo = RandomForestClassifier(random_state=123)
nuevo_modelo.fit(X_train, y_train)

# Importancia por permutación
importancia = permutation_importance(
   estimator    = nuevo_modelo,
    X            = X_train,
    y            = y_train,
    n_repeats    = 5,
    scoring      = 'neg_root_mean_squared_error',
    n_jobs       = multiprocessing.cpu_count() - 1,
    random_state = 123
    )

# Se almacenan los resultados (media y desviación) en un dataframe
#df_importancia['feature'] = X_train.columns
df_importancia = pd.DataFrame(
    { k: importancia[k] for k in ['importances_mean', 'importances_std'] }
    )
df_importancia['predictor'] = X_train.columns
print(df_importancia.sort_values('importances_mean', ascending=False))


# Graficamos los resultados
# ************************************************************************************************
color = ['y','y','g','g','g','g','g']
fig, ax = plt.subplots(figsize=(5, 6))
df_importancia = df_importancia.sort_values('importances_mean', ascending=True)
ax.barh(
    df_importancia['predictor'],
    df_importancia['importances_mean'],
    xerr=df_importancia['importances_std'],
    align='center',
    alpha=1,
    color=color,
    #edgecolor='w',
    #hatch=patterns
)
ax.plot(
    df_importancia['importances_mean'],
    df_importancia['predictor'],
    marker="o",
    linestyle="",
    alpha=0.8,
    color="r"
)
# ax.set_yticklabels(df_importancia['predictor'], fontsize=8)
ax.tick_params(axis='x', labelsize=9)
ax.tick_params(axis='y', labelsize=8)
plt.grid(alpha=.5)
plt.show()

"""###**MODELO DE MAQUINAS DE VECTORES DE SOPORTE**
Support Vector Machine
"""

X_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(
    estudiantes_CEPRE.drop(columns = 'ingreso'),
    estudiantes_CEPRE['ingreso'],
    random_state = 5    # 4 rondas
    )

estudiantes_CEPRE.drop(columns = 'ingreso')

modelo_svm = SVC(kernel='rbf', C=1)      # rbf, linear, poly, sigmoid
m_svm= modelo_svm.fit(X_train_svm, y_train_svm) #modelo_svm

print('Precision SVM:', m_svm.score(X_test_svm, y_test_svm))

# Predicción inicial
predict_svm = m_svm.predict(X_test_svm)
matriz_confussion = confusion_matrix(y_test_svm, predict_svm)

print('\nMATRIZ DE CONFUSION SVM \n***************************************************')
print(matriz_confussion)

f1_score_svm  = f1_score(y_test_svm, predict_svm, average='weighted')
jac_score_svm = jaccard_score(y_test_svm, predict_svm, pos_label=1)

print(f1_score_svm, jac_score_svm)

"""###**MODELO KNN**

Predicción utilizando el modelo de clasificación KNN
"""

modelo_KNN = KNeighborsClassifier(n_neighbors=3)
m_KNN=modelo_KNN.fit(X_train_svm, y_train_svm)

print('Precision KNN:', m_KNN.score(X_train_svm, y_train_svm))

predict_KNN = m_KNN.predict(X_test_svm)
matriz_confussion = confusion_matrix(y_test_svm, predict_KNN)

print('PREDICCIONES: ',predict_KNN[0:30])
print('\nMATRIZ DE CONFUSION KNN \n***************************************************')
matriz_confussion

"""###**MODELO REGRESION LINEAL**

Clasificación utilizando Regresión Lineal
"""

matriz_unos = np.array(np.ones((X_train_svm.shape[0], 1)))
matriz_X = np.append(matriz_unos, X_train_svm.values, axis=1)

matriz_X

matriz_X_Transpuesta = matriz_X.transpose()
matriz_X_inversa = np.linalg.inv(np.matmul(matriz_X_Transpuesta, matriz_X))

matriz_X_TranspuestaY = np.matmul(matriz_X_Transpuesta, y_train_svm)

matriz_Beta = np.matmul(matriz_X_inversa, matriz_X_TranspuestaY)

# Imprimimos los parametros asociados a las preguntas/variables predictoras
print('V-0:', matriz_Beta[0],
      '\nP-1:', matriz_Beta[1],
      '\nP-2:', matriz_Beta[2],
      '\nP-3:', matriz_Beta[3],
      '\nP-4:', matriz_Beta[4],
      '\nP-5:', matriz_Beta[5],
      '\nP-6:', matriz_Beta[6],
      '\nP-7:', matriz_Beta[7])

# Prueba inicial
#                          P1, P2, P3, P4, P5, P6, P7
datos_Prueba = np.array([[1, 1,  5,  5,  5,  1,  1, 5], [1, 4,3,4,5,2,3,5]])
media_Ingresa = np.dot(datos_Prueba, matriz_Beta)

media_Ingresa

# Utilizando la librería Scikit-Learn
modelo_RL = LinearRegression()
m_RL=modelo_RL.fit(X_train_svm, y_train_svm)

coeficientes_RL = m_RL.coef_
interceptor_RL = m_RL.intercept_

# Imprimimos los parametros asociados a las preguntas/variables predictoras
print('V-0:', interceptor_RL,
      '\nPendiente P-1:', coeficientes_RL[0],
      '\nPendiente P-2:', coeficientes_RL[1],
      '\nPendiente P-3:', coeficientes_RL[2],
      '\nPendiente P-4:', coeficientes_RL[3],
      '\nPendiente P-5:', coeficientes_RL[4],
      '\nPendiente P-6:', coeficientes_RL[5],
      '\nPendiente P-7:', coeficientes_RL[6])

# Coeficiente de determinarion R2
# Coeficiente RL mas hacia 1, el modelo es adecuado de lo contrario no es el adecuado
#                y si es negativo, se considera CERO
print('Coeficiente de determinacion RL:', modelo_RL.score(X_test_svm, y_test_svm))

prediccion_RL = m_RL.predict(X_test_svm)
print('RMSE:', (np.sqrt(mean_squared_error(y_test_svm, prediccion_RL))))

prediccion_RL[0:20]


#UTILIZAMOS PICKLE PARA LLEVARLO A OTRO SCRIPT
with open('m_rf.pkl','wb') as rf:
    pickle.dump(m_rf,rf)
    
with open('m_svm.pkl','wb') as svm:
    pickle.dump(m_svm,svm)
    
with open('m_KNN.pkl','wb') as knn:
    pickle.dump(m_KNN,knn)
    
with open('m_RL.pkl','wb') as rl:
    pickle.dump(m_RL,rl)
